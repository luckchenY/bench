#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Bç«™UPä¸»è§†é¢‘é“¾æ¥æ”¶é›†å™¨
åŠŸèƒ½ï¼šæ”¶é›†æŒ‡å®šUPä¸»ä¸»é¡µå†…çš„æ‰€æœ‰è§†é¢‘é“¾æ¥
ä½œè€…ï¼šAI Assistant
"""

import requests
import json
import time
import re
import random
from urllib.parse import urljoin, urlparse
import csv
import os
from typing import List, Dict, Optional
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class BilibiliVideoCollector:
    """Bç«™è§†é¢‘é“¾æ¥æ”¶é›†å™¨"""
    
    def __init__(self):
        self.session = requests.Session()
        
        # å¤šä¸ªUser-Agentè½®æ¢ä½¿ç”¨
        self.user_agents = [
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.107 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:90.0) Gecko/20100101 Firefox/90.0',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.1 Safari/605.1.15'
        ]
        
        self.session.headers.update({
            'User-Agent': random.choice(self.user_agents),
            'Referer': 'https://www.bilibili.com/',
            'Accept': 'application/json, text/plain, */*',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Cache-Control': 'no-cache',
            'Pragma': 'no-cache'
        })
        
        # APIåŸºç¡€URL
        self.base_url = "https://api.bilibili.com"
        
        # è¯·æ±‚è®¡æ•°å™¨
        self.request_count = 0
        
    def _rotate_user_agent(self):
        """è½®æ¢User-Agent"""
        self.session.headers['User-Agent'] = random.choice(self.user_agents)
        
    def _random_delay(self, min_delay=5, max_delay=15):
        """éšæœºå»¶è¿Ÿ - å¢åŠ åŸºç¡€ç­‰å¾…æ—¶é—´"""
        delay = random.uniform(min_delay, max_delay)
        logger.info(f"éšæœºå»¶è¿Ÿ {delay:.2f} ç§’...")
        time.sleep(delay)
        
    def _get_with_retry(self, url: str, params: Optional[Dict] = None, max_retries: int = 5) -> Optional[requests.Response]:
        """å¸¦é‡è¯•æœºåˆ¶çš„GETè¯·æ±‚ - ä½¿ç”¨æ›´é•¿çš„ç­‰å¾…æ—¶é—´"""
        for attempt in range(max_retries):
            try:
                # è½®æ¢User-Agent
                self._rotate_user_agent()
                
                # éšæœºå»¶è¿Ÿ - æ¯æ¬¡è¯·æ±‚å‰éƒ½å»¶è¿Ÿ
                if self.request_count > 0:
                    self._random_delay(8, 20)  # å¢åŠ å»¶è¿ŸèŒƒå›´
                else:
                    # ç¬¬ä¸€æ¬¡è¯·æ±‚ä¹Ÿå»¶è¿Ÿä¸€ä¸‹
                    time.sleep(random.uniform(3, 8))
                
                response = self.session.get(url, params=params, timeout=30)  # å¢åŠ è¶…æ—¶æ—¶é—´
                self.request_count += 1
                
                # æ£€æŸ¥å“åº”çŠ¶æ€
                if response.status_code == 200:
                    return response
                elif response.status_code == 429:  # Too Many Requests
                    # ä½¿ç”¨æŒ‡æ•°é€€é¿ç­–ç•¥
                    wait_time = min(60 * (2 ** attempt), 600)  # æœ€å¤§ç­‰å¾…10åˆ†é’Ÿ
                    logger.warning(f"è¯·æ±‚è¿‡äºé¢‘ç¹ (429)ï¼Œç­‰å¾… {wait_time} ç§’...")
                    time.sleep(wait_time)
                else:
                    logger.error(f"HTTPé”™è¯¯ {response.status_code}: {response.text}")
                    
            except requests.exceptions.RequestException as e:
                logger.error(f"è¯·æ±‚å¼‚å¸¸ (ç¬¬ {attempt + 1} æ¬¡): {e}")
                if attempt < max_retries - 1:
                    # ä½¿ç”¨æŒ‡æ•°é€€é¿ç­–ç•¥
                    wait_time = min(30 * (2 ** attempt), 300)  # æœ€å¤§ç­‰å¾…5åˆ†é’Ÿ
                    logger.info(f"ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    time.sleep(wait_time)
                    
        return None
    
    def get_uid_from_url(self, url: str) -> Optional[str]:
        """ä»UPä¸»ä¸»é¡µURLä¸­æå–UID"""
        patterns = [
            r'space\.bilibili\.com/(\d+)',
            r'uid=(\d+)',
            r'/(\d+)/?$'
        ]
        
        for pattern in patterns:
            match = re.search(pattern, url)
            if match:
                return match.group(1)
        return None
    
    def get_user_info(self, uid: str) -> Optional[Dict]:
        """è·å–ç”¨æˆ·ä¿¡æ¯"""
        try:
            url = f"{self.base_url}/x/space/acc/info"
            params = {'mid': uid}
            
            response = self._get_with_retry(url, params)
            if not response:
                return None
                
            data = response.json()
            if data['code'] == 0:
                return data['data']
            else:
                error_msg = data.get('message', 'æœªçŸ¥é”™è¯¯')
                logger.error(f"è·å–ç”¨æˆ·ä¿¡æ¯å¤±è´¥: {error_msg}")
                return None
                
        except Exception as e:
            logger.error(f"è·å–ç”¨æˆ·ä¿¡æ¯æ—¶å‡ºé”™: {e}")
            return None
    
    def get_user_videos(self, uid: str, page: int = 1, page_size: int = 30) -> Optional[Dict]:
        """è·å–ç”¨æˆ·è§†é¢‘åˆ—è¡¨"""
        try:
            url = f"{self.base_url}/x/space/arc/search"
            params = {
                'mid': uid,
                'pn': page,
                'ps': page_size,
                'jsonp': 'jsonp'
            }
            
            response = self._get_with_retry(url, params)
            if not response:
                return None
                
            data = response.json()
            if data['code'] == 0:
                return data['data']
            else:
                error_msg = data.get('message', 'æœªçŸ¥é”™è¯¯')
                logger.error(f"è·å–è§†é¢‘åˆ—è¡¨å¤±è´¥: {error_msg}")
                return None
                
        except Exception as e:
            logger.error(f"è·å–è§†é¢‘åˆ—è¡¨æ—¶å‡ºé”™: {e}")
            return None
    
    def collect_all_videos(self, uid: str, max_pages: int = 100) -> List[Dict]:
        """æ”¶é›†ç”¨æˆ·æ‰€æœ‰è§†é¢‘ä¿¡æ¯"""
        all_videos = []
        page = 1
        consecutive_errors = 0
        max_consecutive_errors = 3
        
        logger.info(f"å¼€å§‹æ”¶é›†UID {uid} çš„è§†é¢‘...")
        
        while page <= max_pages:
            logger.info(f"æ­£åœ¨è·å–ç¬¬ {page} é¡µè§†é¢‘...")
            
            data = self.get_user_videos(uid, page)
            if not data:
                consecutive_errors += 1
                logger.warning(f"ç¬¬ {page} é¡µè·å–å¤±è´¥ï¼Œè¿ç»­å¤±è´¥æ¬¡æ•°: {consecutive_errors}")
                
                if consecutive_errors >= max_consecutive_errors:
                    logger.error(f"è¿ç»­å¤±è´¥ {max_consecutive_errors} æ¬¡ï¼Œåœæ­¢æ”¶é›†")
                    break
                    
                # ä½¿ç”¨æŒ‡æ•°é€€é¿ç­–ç•¥ç­‰å¾…æ›´é•¿æ—¶é—´
                wait_time = min(60 * (2 ** consecutive_errors), 300)  # æœ€å¤§ç­‰å¾…10åˆ†é’Ÿ
                logger.info(f"ç­‰å¾… {wait_time} ç§’åç»§ç»­...")
                time.sleep(wait_time)
                continue
            else:
                consecutive_errors = 0  # é‡ç½®é”™è¯¯è®¡æ•°
                
            videos = data.get('list', {}).get('vlist', [])
            if not videos:
                logger.info("æ²¡æœ‰æ›´å¤šè§†é¢‘äº†")
                break
                
            for video in videos:
                video_info = {
                    'bvid': video.get('bvid', ''),
                    'aid': video.get('aid', ''),
                    'title': video.get('title', ''),
                    'description': video.get('description', ''),
                    'duration': video.get('duration', ''),
                    'view': video.get('play', 0),
                    'danmaku': video.get('video_review', 0),
                    'reply': video.get('comment', 0),
                    'favorite': video.get('favorites', 0),
                    'coin': video.get('coins', 0),
                    'share': video.get('share', 0),
                    'like': video.get('like', 0),
                    'created': video.get('created', 0),
                    'pic': video.get('pic', ''),
                    'video_url': f"https://www.bilibili.com/video/{video.get('bvid', '')}",
                    'page': page
                }
                all_videos.append(video_info)
            
            logger.info(f"ç¬¬ {page} é¡µæ”¶é›†åˆ° {len(videos)} ä¸ªè§†é¢‘")
            
            # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æ›´å¤šé¡µ
            if len(videos) < 30:  # æ¯é¡µé»˜è®¤30ä¸ªè§†é¢‘
                logger.info("å·²åˆ°è¾¾æœ€åä¸€é¡µ")
                break
                
            page += 1
        
        logger.info(f"å…±æ”¶é›†åˆ° {len(all_videos)} ä¸ªè§†é¢‘")
        return all_videos
    
    def save_to_csv(self, videos: List[Dict], filename: str):
        """ä¿å­˜è§†é¢‘ä¿¡æ¯åˆ°CSVæ–‡ä»¶"""
        if not videos:
            logger.warning("æ²¡æœ‰è§†é¢‘æ•°æ®å¯ä¿å­˜")
            return
            
        try:
            with open(filename, 'w', newline='', encoding='utf-8-sig') as csvfile:
                fieldnames = [
                    'bvid', 'aid', 'title', 'description', 'duration', 
                    'view', 'danmaku', 'reply', 'favorite', 'coin', 
                    'share', 'like', 'created', 'pic', 'video_url', 'page'
                ]
                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
                writer.writeheader()
                writer.writerows(videos)
                
            logger.info(f"è§†é¢‘ä¿¡æ¯å·²ä¿å­˜åˆ° {filename}")
            
        except Exception as e:
            logger.error(f"ä¿å­˜CSVæ–‡ä»¶æ—¶å‡ºé”™: {e}")
    
    def save_urls_only(self, videos: List[Dict], filename: str):
        """åªä¿å­˜è§†é¢‘é“¾æ¥åˆ°æ–‡æœ¬æ–‡ä»¶"""
        if not videos:
            logger.warning("æ²¡æœ‰è§†é¢‘æ•°æ®å¯ä¿å­˜")
            return
            
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                for video in videos:
                    f.write(f"{video['video_url']}\n")
                    
            logger.info(f"è§†é¢‘é“¾æ¥å·²ä¿å­˜åˆ° {filename}")
            
        except Exception as e:
            logger.error(f"ä¿å­˜é“¾æ¥æ–‡ä»¶æ—¶å‡ºé”™: {e}")
    
    def collect_from_url(self, up_url: str, save_csv: bool = True, save_urls: bool = True) -> List[Dict]:
        """ä»UPä¸»ä¸»é¡µURLæ”¶é›†æ‰€æœ‰è§†é¢‘"""
        # æå–UID
        uid = self.get_uid_from_url(up_url)
        if not uid:
            logger.error("æ— æ³•ä»URLä¸­æå–UID")
            return []
        
        # è·å–ç”¨æˆ·ä¿¡æ¯
        user_info = self.get_user_info(uid)
        if user_info:
            logger.info(f"UPä¸»: {user_info.get('name', 'Unknown')}")
        
        # æ”¶é›†æ‰€æœ‰è§†é¢‘
        videos = self.collect_all_videos(uid)
        
        if videos:
            # ç”Ÿæˆæ–‡ä»¶å
            base_filename = f"bilibili_videos_{uid}"
            
            if save_csv:
                csv_filename = f"{base_filename}.csv"
                self.save_to_csv(videos, csv_filename)
            
            if save_urls:
                urls_filename = f"{base_filename}_urls.txt"
                self.save_urls_only(videos, urls_filename)
        
        return videos

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 50)
    print("Bç«™UPä¸»è§†é¢‘é“¾æ¥æ”¶é›†å™¨")
    print("=" * 50)
    
    collector = BilibiliVideoCollector()
    
    while True:
        print("\nè¯·é€‰æ‹©æ“ä½œ:")
        print("1. è¾“å…¥UPä¸»ä¸»é¡µURLæ”¶é›†è§†é¢‘")
        print("2. è¾“å…¥UIDç›´æ¥æ”¶é›†è§†é¢‘")
        print("3. é€€å‡º")
        
        choice = input("\nè¯·è¾“å…¥é€‰æ‹© (1-3): ").strip()
        
        if choice == '1':
            up_url = input("è¯·è¾“å…¥UPä¸»ä¸»é¡µURL: ").strip()
            if up_url:
                videos = collector.collect_from_url(up_url)
                if videos:
                    print(f"\nâœ… æˆåŠŸæ”¶é›†åˆ° {len(videos)} ä¸ªè§†é¢‘!")
                    print("ğŸ“ æ–‡ä»¶å·²ä¿å­˜åˆ°å½“å‰ç›®å½•")
                else:
                    print("âŒ æ”¶é›†å¤±è´¥ï¼Œè¯·æ£€æŸ¥URLæ˜¯å¦æ­£ç¡®")
        
        elif choice == '2':
            uid = input("è¯·è¾“å…¥UPä¸»UID: ").strip()
            if uid and uid.isdigit():
                videos = collector.collect_all_videos(uid)
                if videos:
                    base_filename = f"bilibili_videos_{uid}"
                    collector.save_to_csv(videos, f"{base_filename}.csv")
                    collector.save_urls_only(videos, f"{base_filename}_urls.txt")
                    print(f"\nâœ… æˆåŠŸæ”¶é›†åˆ° {len(videos)} ä¸ªè§†é¢‘!")
                    print("ğŸ“ æ–‡ä»¶å·²ä¿å­˜åˆ°å½“å‰ç›®å½•")
                else:
                    print("âŒ æ”¶é›†å¤±è´¥ï¼Œè¯·æ£€æŸ¥UIDæ˜¯å¦æ­£ç¡®")
            else:
                print("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„UID")
        
        elif choice == '3':
            print("ğŸ‘‹ å†è§!")
            break
        
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")

if __name__ == "__main__":
    main() 